# Ollama Chat

A simple chat UI built using Next.js, integrated with Ollama model detection. This project was developed as an experiment to learn more about Ollama and how to use its API endpoint for projects.

## Features

- **Next JS**: Utilizes Next JS a framework for building the user interface.
- **Ollama**: Compatible with installed Ollama models.
- **Markdown Render**: For enhanced readability of AI messages, and to easily copy generated code.

## Purpose

The primary purpose of Ollama Chat is to explore and understand how to implement Ollamaâ€™s API endpoint and to create a simple UI for local Ollama models.

## Installation

To get started with the Ollama Chat, follow these steps:

1. Clone the repository:
   ```bash
   git clone https://github.com/jei3m/ollama-chat.git
   ```

2. Navigate to the project directory:
   ```bash
   cd ollama-chat
   ```

3. Install the dependencies:
   ```bash
   npm install
   ```

4. Open Ollama:
   Make sure Ollama is open and that you have local models installed.
